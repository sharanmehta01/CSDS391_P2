Explaining the neural network architecture (file csds391_p2.ipynb)


Preprocessing the data -  
We use tensorflow (integrated with keras) to set up our neural network. Our goal is to train the model on the full iris data set (3 species, 4 attributes). 

After importing the required packages, we read the CSV file using pandas and rename each of the speicies as floats (setosa = 0.0, versicolor = 1.0, virginica = 2.0) to avoid erros regaridng mixed data types.

We create two numpy arrays, one for the four different attriubtes/features over which the model needs to be trained and one for the labels (name of the speicies itself).

An important part of of preprocessing the data is normalizing the x-axis vaues. This transforms the range from 0.0-8.0 to 0.0-1.0 and makes it easier for the model to learn. The normalization is done using the MinMaxScaler

The other important part regarding setting up data is to shuffle it once. This will help with validation later on. 


Traiining the model - 
We use a sequential model with 2 hidden layers with the third layer being the output layer. The output layer uses the softmax activation to produce probabilites.

We set our model optimizer to be SGD (Stochastic Gradient Descent) rather than the default Adam optimizer. Our lerning rate is set at 0.05 and we use sparse categorical crossentropy for our loss calculation.

Next we set the x values as the iris features and the y values as the iris labels. We have 15 batches with each batch learning 10 samples at once and this is done 50 times. 

We took out 0.1 (10%) of the shuffled data as a sample to validate the model later on. This means that this 10% or 15 samples is previously unseen by the model and we can use it to test how well the model can predict their labels. 

Shuffle is set to true to prevent the model from simply learning the order of the features and labels.

After 50 epochs we can see that our model is trained and is 97.78% accurate. The validation accuracy of 100% shows the the model truly is well trained. 



Contrasting with K-means clustering - 
We next set up a k-means clustering model with 3 clusters. We don't train this model but let it start predicting on its own. 

We see the output array after the model is passed over the full iris dataset and the results seem fairly good with most of the samples that were close together idenitifes as being under the same speicies. 

