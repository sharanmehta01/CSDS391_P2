{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n# Make numpy values easier to read.\nnp.set_printoptions(precision=3, suppress=True)\nfrom random import randint\nfrom sklearn.utils import shuffle \nfrom sklearn.preprocessing import MinMaxScaler\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":221,"outputs":[{"output_type":"stream","text":"/kaggle/input/iris-data/irisdata.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras.layers import Activation, Dense\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.metrics import categorical_crossentropy","execution_count":222,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iris_train = pd.read_csv(\"../input/iris-data/irisdata.csv\", header = 0, names = [\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\",\"species\"])\niris_train['species'] = np.where(iris_train['species'] == 'setosa', 0.0, iris_train['species'])\niris_train['species'] = np.where(iris_train['species'] == 'versicolor', 1.0, iris_train['species'])\niris_train['species'] = np.where(iris_train['species'] == 'virginica', 2.0, iris_train['species'])\niris_train['species'] = np.asarray(iris_train['species']).astype('float32')\niris_train.head()","execution_count":223,"outputs":[{"output_type":"execute_result","execution_count":223,"data":{"text/plain":"   sepal_length  sepal_width  petal_length  petal_width  species\n0           5.1          3.5           1.4          0.2      0.0\n1           4.9          3.0           1.4          0.2      0.0\n2           4.7          3.2           1.3          0.2      0.0\n3           4.6          3.1           1.5          0.2      0.0\n4           5.0          3.6           1.4          0.2      0.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal_length</th>\n      <th>sepal_width</th>\n      <th>petal_length</th>\n      <th>petal_width</th>\n      <th>species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"iris_features = iris_train.copy()\n#iris_features['species'] = np.where(iris_features['species'] == 'setosa', 0.0, iris_features['species'])\n#iris_features['species'] = np.where(iris_features['species'] == 'versicolor', 1.0, iris_features['species'])\n#iris_features['species'] = np.where(iris_features['species'] == 'virginica', 2.0, iris_features['species'])\niris_labels = iris_features.pop('species')\n","execution_count":224,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iris_features = np.array(iris_features)\niris_features","execution_count":225,"outputs":[{"output_type":"execute_result","execution_count":225,"data":{"text/plain":"array([[5.1, 3.5, 1.4, 0.2],\n       [4.9, 3. , 1.4, 0.2],\n       [4.7, 3.2, 1.3, 0.2],\n       [4.6, 3.1, 1.5, 0.2],\n       [5. , 3.6, 1.4, 0.2],\n       [5.4, 3.9, 1.7, 0.4],\n       [4.6, 3.4, 1.4, 0.3],\n       [5. , 3.4, 1.5, 0.2],\n       [4.4, 2.9, 1.4, 0.2],\n       [4.9, 3.1, 1.5, 0.1],\n       [5.4, 3.7, 1.5, 0.2],\n       [4.8, 3.4, 1.6, 0.2],\n       [4.8, 3. , 1.4, 0.1],\n       [4.3, 3. , 1.1, 0.1],\n       [5.8, 4. , 1.2, 0.2],\n       [5.7, 4.4, 1.5, 0.4],\n       [5.4, 3.9, 1.3, 0.4],\n       [5.1, 3.5, 1.4, 0.3],\n       [5.7, 3.8, 1.7, 0.3],\n       [5.1, 3.8, 1.5, 0.3],\n       [5.4, 3.4, 1.7, 0.2],\n       [5.1, 3.7, 1.5, 0.4],\n       [4.6, 3.6, 1. , 0.2],\n       [5.1, 3.3, 1.7, 0.5],\n       [4.8, 3.4, 1.9, 0.2],\n       [5. , 3. , 1.6, 0.2],\n       [5. , 3.4, 1.6, 0.4],\n       [5.2, 3.5, 1.5, 0.2],\n       [5.2, 3.4, 1.4, 0.2],\n       [4.7, 3.2, 1.6, 0.2],\n       [4.8, 3.1, 1.6, 0.2],\n       [5.4, 3.4, 1.5, 0.4],\n       [5.2, 4.1, 1.5, 0.1],\n       [5.5, 4.2, 1.4, 0.2],\n       [4.9, 3.1, 1.5, 0.1],\n       [5. , 3.2, 1.2, 0.2],\n       [5.5, 3.5, 1.3, 0.2],\n       [4.9, 3.1, 1.5, 0.1],\n       [4.4, 3. , 1.3, 0.2],\n       [5.1, 3.4, 1.5, 0.2],\n       [5. , 3.5, 1.3, 0.3],\n       [4.5, 2.3, 1.3, 0.3],\n       [4.4, 3.2, 1.3, 0.2],\n       [5. , 3.5, 1.6, 0.6],\n       [5.1, 3.8, 1.9, 0.4],\n       [4.8, 3. , 1.4, 0.3],\n       [5.1, 3.8, 1.6, 0.2],\n       [4.6, 3.2, 1.4, 0.2],\n       [5.3, 3.7, 1.5, 0.2],\n       [5. , 3.3, 1.4, 0.2],\n       [7. , 3.2, 4.7, 1.4],\n       [6.4, 3.2, 4.5, 1.5],\n       [6.9, 3.1, 4.9, 1.5],\n       [5.5, 2.3, 4. , 1.3],\n       [6.5, 2.8, 4.6, 1.5],\n       [5.7, 2.8, 4.5, 1.3],\n       [6.3, 3.3, 4.7, 1.6],\n       [4.9, 2.4, 3.3, 1. ],\n       [6.6, 2.9, 4.6, 1.3],\n       [5.2, 2.7, 3.9, 1.4],\n       [5. , 2. , 3.5, 1. ],\n       [5.9, 3. , 4.2, 1.5],\n       [6. , 2.2, 4. , 1. ],\n       [6.1, 2.9, 4.7, 1.4],\n       [5.6, 2.9, 3.6, 1.3],\n       [6.7, 3.1, 4.4, 1.4],\n       [5.6, 3. , 4.5, 1.5],\n       [5.8, 2.7, 4.1, 1. ],\n       [6.2, 2.2, 4.5, 1.5],\n       [5.6, 2.5, 3.9, 1.1],\n       [5.9, 3.2, 4.8, 1.8],\n       [6.1, 2.8, 4. , 1.3],\n       [6.3, 2.5, 4.9, 1.5],\n       [6.1, 2.8, 4.7, 1.2],\n       [6.4, 2.9, 4.3, 1.3],\n       [6.6, 3. , 4.4, 1.4],\n       [6.8, 2.8, 4.8, 1.4],\n       [6.7, 3. , 5. , 1.7],\n       [6. , 2.9, 4.5, 1.5],\n       [5.7, 2.6, 3.5, 1. ],\n       [5.5, 2.4, 3.8, 1.1],\n       [5.5, 2.4, 3.7, 1. ],\n       [5.8, 2.7, 3.9, 1.2],\n       [6. , 2.7, 5.1, 1.6],\n       [5.4, 3. , 4.5, 1.5],\n       [6. , 3.4, 4.5, 1.6],\n       [6.7, 3.1, 4.7, 1.5],\n       [6.3, 2.3, 4.4, 1.3],\n       [5.6, 3. , 4.1, 1.3],\n       [5.5, 2.5, 4. , 1.3],\n       [5.5, 2.6, 4.4, 1.2],\n       [6.1, 3. , 4.6, 1.4],\n       [5.8, 2.6, 4. , 1.2],\n       [5. , 2.3, 3.3, 1. ],\n       [5.6, 2.7, 4.2, 1.3],\n       [5.7, 3. , 4.2, 1.2],\n       [5.7, 2.9, 4.2, 1.3],\n       [6.2, 2.9, 4.3, 1.3],\n       [5.1, 2.5, 3. , 1.1],\n       [5.7, 2.8, 4.1, 1.3],\n       [6.3, 3.3, 6. , 2.5],\n       [5.8, 2.7, 5.1, 1.9],\n       [7.1, 3. , 5.9, 2.1],\n       [6.3, 2.9, 5.6, 1.8],\n       [6.5, 3. , 5.8, 2.2],\n       [7.6, 3. , 6.6, 2.1],\n       [4.9, 2.5, 4.5, 1.7],\n       [7.3, 2.9, 6.3, 1.8],\n       [6.7, 2.5, 5.8, 1.8],\n       [7.2, 3.6, 6.1, 2.5],\n       [6.5, 3.2, 5.1, 2. ],\n       [6.4, 2.7, 5.3, 1.9],\n       [6.8, 3. , 5.5, 2.1],\n       [5.7, 2.5, 5. , 2. ],\n       [5.8, 2.8, 5.1, 2.4],\n       [6.4, 3.2, 5.3, 2.3],\n       [6.5, 3. , 5.5, 1.8],\n       [7.7, 3.8, 6.7, 2.2],\n       [7.7, 2.6, 6.9, 2.3],\n       [6. , 2.2, 5. , 1.5],\n       [6.9, 3.2, 5.7, 2.3],\n       [5.6, 2.8, 4.9, 2. ],\n       [7.7, 2.8, 6.7, 2. ],\n       [6.3, 2.7, 4.9, 1.8],\n       [6.7, 3.3, 5.7, 2.1],\n       [7.2, 3.2, 6. , 1.8],\n       [6.2, 2.8, 4.8, 1.8],\n       [6.1, 3. , 4.9, 1.8],\n       [6.4, 2.8, 5.6, 2.1],\n       [7.2, 3. , 5.8, 1.6],\n       [7.4, 2.8, 6.1, 1.9],\n       [7.9, 3.8, 6.4, 2. ],\n       [6.4, 2.8, 5.6, 2.2],\n       [6.3, 2.8, 5.1, 1.5],\n       [6.1, 2.6, 5.6, 1.4],\n       [7.7, 3. , 6.1, 2.3],\n       [6.3, 3.4, 5.6, 2.4],\n       [6.4, 3.1, 5.5, 1.8],\n       [6. , 3. , 4.8, 1.8],\n       [6.9, 3.1, 5.4, 2.1],\n       [6.7, 3.1, 5.6, 2.4],\n       [6.9, 3.1, 5.1, 2.3],\n       [5.8, 2.7, 5.1, 1.9],\n       [6.8, 3.2, 5.9, 2.3],\n       [6.7, 3.3, 5.7, 2.5],\n       [6.7, 3. , 5.2, 2.3],\n       [6.3, 2.5, 5. , 1.9],\n       [6.5, 3. , 5.2, 2. ],\n       [6.2, 3.4, 5.4, 2.3],\n       [5.9, 3. , 5.1, 1.8]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#normalize = preprocessing.Normalization()\n\n#normalize.adapt(iris_features)\nscaler = MinMaxScaler(feature_range=(0,1))\niris_features = scaler.fit_transform(iris_features.reshape(-4,4))\niris_features","execution_count":226,"outputs":[{"output_type":"execute_result","execution_count":226,"data":{"text/plain":"array([[0.222, 0.625, 0.068, 0.042],\n       [0.167, 0.417, 0.068, 0.042],\n       [0.111, 0.5  , 0.051, 0.042],\n       [0.083, 0.458, 0.085, 0.042],\n       [0.194, 0.667, 0.068, 0.042],\n       [0.306, 0.792, 0.119, 0.125],\n       [0.083, 0.583, 0.068, 0.083],\n       [0.194, 0.583, 0.085, 0.042],\n       [0.028, 0.375, 0.068, 0.042],\n       [0.167, 0.458, 0.085, 0.   ],\n       [0.306, 0.708, 0.085, 0.042],\n       [0.139, 0.583, 0.102, 0.042],\n       [0.139, 0.417, 0.068, 0.   ],\n       [0.   , 0.417, 0.017, 0.   ],\n       [0.417, 0.833, 0.034, 0.042],\n       [0.389, 1.   , 0.085, 0.125],\n       [0.306, 0.792, 0.051, 0.125],\n       [0.222, 0.625, 0.068, 0.083],\n       [0.389, 0.75 , 0.119, 0.083],\n       [0.222, 0.75 , 0.085, 0.083],\n       [0.306, 0.583, 0.119, 0.042],\n       [0.222, 0.708, 0.085, 0.125],\n       [0.083, 0.667, 0.   , 0.042],\n       [0.222, 0.542, 0.119, 0.167],\n       [0.139, 0.583, 0.153, 0.042],\n       [0.194, 0.417, 0.102, 0.042],\n       [0.194, 0.583, 0.102, 0.125],\n       [0.25 , 0.625, 0.085, 0.042],\n       [0.25 , 0.583, 0.068, 0.042],\n       [0.111, 0.5  , 0.102, 0.042],\n       [0.139, 0.458, 0.102, 0.042],\n       [0.306, 0.583, 0.085, 0.125],\n       [0.25 , 0.875, 0.085, 0.   ],\n       [0.333, 0.917, 0.068, 0.042],\n       [0.167, 0.458, 0.085, 0.   ],\n       [0.194, 0.5  , 0.034, 0.042],\n       [0.333, 0.625, 0.051, 0.042],\n       [0.167, 0.458, 0.085, 0.   ],\n       [0.028, 0.417, 0.051, 0.042],\n       [0.222, 0.583, 0.085, 0.042],\n       [0.194, 0.625, 0.051, 0.083],\n       [0.056, 0.125, 0.051, 0.083],\n       [0.028, 0.5  , 0.051, 0.042],\n       [0.194, 0.625, 0.102, 0.208],\n       [0.222, 0.75 , 0.153, 0.125],\n       [0.139, 0.417, 0.068, 0.083],\n       [0.222, 0.75 , 0.102, 0.042],\n       [0.083, 0.5  , 0.068, 0.042],\n       [0.278, 0.708, 0.085, 0.042],\n       [0.194, 0.542, 0.068, 0.042],\n       [0.75 , 0.5  , 0.627, 0.542],\n       [0.583, 0.5  , 0.593, 0.583],\n       [0.722, 0.458, 0.661, 0.583],\n       [0.333, 0.125, 0.508, 0.5  ],\n       [0.611, 0.333, 0.61 , 0.583],\n       [0.389, 0.333, 0.593, 0.5  ],\n       [0.556, 0.542, 0.627, 0.625],\n       [0.167, 0.167, 0.39 , 0.375],\n       [0.639, 0.375, 0.61 , 0.5  ],\n       [0.25 , 0.292, 0.492, 0.542],\n       [0.194, 0.   , 0.424, 0.375],\n       [0.444, 0.417, 0.542, 0.583],\n       [0.472, 0.083, 0.508, 0.375],\n       [0.5  , 0.375, 0.627, 0.542],\n       [0.361, 0.375, 0.441, 0.5  ],\n       [0.667, 0.458, 0.576, 0.542],\n       [0.361, 0.417, 0.593, 0.583],\n       [0.417, 0.292, 0.525, 0.375],\n       [0.528, 0.083, 0.593, 0.583],\n       [0.361, 0.208, 0.492, 0.417],\n       [0.444, 0.5  , 0.644, 0.708],\n       [0.5  , 0.333, 0.508, 0.5  ],\n       [0.556, 0.208, 0.661, 0.583],\n       [0.5  , 0.333, 0.627, 0.458],\n       [0.583, 0.375, 0.559, 0.5  ],\n       [0.639, 0.417, 0.576, 0.542],\n       [0.694, 0.333, 0.644, 0.542],\n       [0.667, 0.417, 0.678, 0.667],\n       [0.472, 0.375, 0.593, 0.583],\n       [0.389, 0.25 , 0.424, 0.375],\n       [0.333, 0.167, 0.475, 0.417],\n       [0.333, 0.167, 0.458, 0.375],\n       [0.417, 0.292, 0.492, 0.458],\n       [0.472, 0.292, 0.695, 0.625],\n       [0.306, 0.417, 0.593, 0.583],\n       [0.472, 0.583, 0.593, 0.625],\n       [0.667, 0.458, 0.627, 0.583],\n       [0.556, 0.125, 0.576, 0.5  ],\n       [0.361, 0.417, 0.525, 0.5  ],\n       [0.333, 0.208, 0.508, 0.5  ],\n       [0.333, 0.25 , 0.576, 0.458],\n       [0.5  , 0.417, 0.61 , 0.542],\n       [0.417, 0.25 , 0.508, 0.458],\n       [0.194, 0.125, 0.39 , 0.375],\n       [0.361, 0.292, 0.542, 0.5  ],\n       [0.389, 0.417, 0.542, 0.458],\n       [0.389, 0.375, 0.542, 0.5  ],\n       [0.528, 0.375, 0.559, 0.5  ],\n       [0.222, 0.208, 0.339, 0.417],\n       [0.389, 0.333, 0.525, 0.5  ],\n       [0.556, 0.542, 0.847, 1.   ],\n       [0.417, 0.292, 0.695, 0.75 ],\n       [0.778, 0.417, 0.831, 0.833],\n       [0.556, 0.375, 0.78 , 0.708],\n       [0.611, 0.417, 0.814, 0.875],\n       [0.917, 0.417, 0.949, 0.833],\n       [0.167, 0.208, 0.593, 0.667],\n       [0.833, 0.375, 0.898, 0.708],\n       [0.667, 0.208, 0.814, 0.708],\n       [0.806, 0.667, 0.864, 1.   ],\n       [0.611, 0.5  , 0.695, 0.792],\n       [0.583, 0.292, 0.729, 0.75 ],\n       [0.694, 0.417, 0.763, 0.833],\n       [0.389, 0.208, 0.678, 0.792],\n       [0.417, 0.333, 0.695, 0.958],\n       [0.583, 0.5  , 0.729, 0.917],\n       [0.611, 0.417, 0.763, 0.708],\n       [0.944, 0.75 , 0.966, 0.875],\n       [0.944, 0.25 , 1.   , 0.917],\n       [0.472, 0.083, 0.678, 0.583],\n       [0.722, 0.5  , 0.797, 0.917],\n       [0.361, 0.333, 0.661, 0.792],\n       [0.944, 0.333, 0.966, 0.792],\n       [0.556, 0.292, 0.661, 0.708],\n       [0.667, 0.542, 0.797, 0.833],\n       [0.806, 0.5  , 0.847, 0.708],\n       [0.528, 0.333, 0.644, 0.708],\n       [0.5  , 0.417, 0.661, 0.708],\n       [0.583, 0.333, 0.78 , 0.833],\n       [0.806, 0.417, 0.814, 0.625],\n       [0.861, 0.333, 0.864, 0.75 ],\n       [1.   , 0.75 , 0.915, 0.792],\n       [0.583, 0.333, 0.78 , 0.875],\n       [0.556, 0.333, 0.695, 0.583],\n       [0.5  , 0.25 , 0.78 , 0.542],\n       [0.944, 0.417, 0.864, 0.917],\n       [0.556, 0.583, 0.78 , 0.958],\n       [0.583, 0.458, 0.763, 0.708],\n       [0.472, 0.417, 0.644, 0.708],\n       [0.722, 0.458, 0.746, 0.833],\n       [0.667, 0.458, 0.78 , 0.958],\n       [0.722, 0.458, 0.695, 0.917],\n       [0.417, 0.292, 0.695, 0.75 ],\n       [0.694, 0.5  , 0.831, 0.917],\n       [0.667, 0.542, 0.797, 1.   ],\n       [0.667, 0.417, 0.712, 0.917],\n       [0.556, 0.208, 0.678, 0.75 ],\n       [0.611, 0.417, 0.712, 0.792],\n       [0.528, 0.583, 0.746, 0.917],\n       [0.444, 0.417, 0.695, 0.708]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"iris_labels, iris_features = shuffle(iris_labels,iris_features)\niris_features","execution_count":227,"outputs":[{"output_type":"execute_result","execution_count":227,"data":{"text/plain":"array([[0.194, 0.125, 0.39 , 0.375],\n       [0.333, 0.625, 0.051, 0.042],\n       [0.222, 0.625, 0.068, 0.083],\n       [0.194, 0.   , 0.424, 0.375],\n       [0.306, 0.583, 0.119, 0.042],\n       [0.389, 0.75 , 0.119, 0.083],\n       [0.417, 0.292, 0.525, 0.375],\n       [0.194, 0.542, 0.068, 0.042],\n       [1.   , 0.75 , 0.915, 0.792],\n       [0.639, 0.375, 0.61 , 0.5  ],\n       [0.472, 0.083, 0.508, 0.375],\n       [0.417, 0.292, 0.695, 0.75 ],\n       [0.944, 0.417, 0.864, 0.917],\n       [0.306, 0.708, 0.085, 0.042],\n       [0.306, 0.792, 0.119, 0.125],\n       [0.778, 0.417, 0.831, 0.833],\n       [0.694, 0.333, 0.644, 0.542],\n       [0.306, 0.583, 0.085, 0.125],\n       [0.5  , 0.417, 0.61 , 0.542],\n       [0.472, 0.417, 0.644, 0.708],\n       [0.25 , 0.625, 0.085, 0.042],\n       [0.583, 0.458, 0.763, 0.708],\n       [0.389, 0.375, 0.542, 0.5  ],\n       [0.583, 0.5  , 0.729, 0.917],\n       [0.556, 0.292, 0.661, 0.708],\n       [0.417, 0.833, 0.034, 0.042],\n       [0.361, 0.292, 0.542, 0.5  ],\n       [0.222, 0.208, 0.339, 0.417],\n       [0.5  , 0.333, 0.627, 0.458],\n       [0.944, 0.333, 0.966, 0.792],\n       [0.25 , 0.875, 0.085, 0.   ],\n       [0.806, 0.5  , 0.847, 0.708],\n       [0.667, 0.417, 0.712, 0.917],\n       [0.667, 0.542, 0.797, 1.   ],\n       [0.389, 1.   , 0.085, 0.125],\n       [0.222, 0.625, 0.068, 0.042],\n       [0.722, 0.458, 0.695, 0.917],\n       [0.389, 0.417, 0.542, 0.458],\n       [0.194, 0.625, 0.102, 0.208],\n       [0.333, 0.125, 0.508, 0.5  ],\n       [0.389, 0.333, 0.593, 0.5  ],\n       [0.694, 0.417, 0.763, 0.833],\n       [0.806, 0.667, 0.864, 1.   ],\n       [0.583, 0.333, 0.78 , 0.875],\n       [0.667, 0.458, 0.78 , 0.958],\n       [0.194, 0.583, 0.085, 0.042],\n       [0.861, 0.333, 0.864, 0.75 ],\n       [0.167, 0.417, 0.068, 0.042],\n       [0.556, 0.583, 0.78 , 0.958],\n       [0.194, 0.667, 0.068, 0.042],\n       [0.444, 0.417, 0.695, 0.708],\n       [0.833, 0.375, 0.898, 0.708],\n       [0.472, 0.292, 0.695, 0.625],\n       [0.528, 0.375, 0.559, 0.5  ],\n       [0.5  , 0.25 , 0.78 , 0.542],\n       [0.028, 0.375, 0.068, 0.042],\n       [0.722, 0.458, 0.661, 0.583],\n       [0.583, 0.333, 0.78 , 0.833],\n       [0.306, 0.417, 0.593, 0.583],\n       [0.139, 0.417, 0.068, 0.083],\n       [0.083, 0.667, 0.   , 0.042],\n       [0.694, 0.5  , 0.831, 0.917],\n       [0.556, 0.125, 0.576, 0.5  ],\n       [0.333, 0.208, 0.508, 0.5  ],\n       [0.5  , 0.417, 0.661, 0.708],\n       [0.194, 0.625, 0.051, 0.083],\n       [0.25 , 0.292, 0.492, 0.542],\n       [0.722, 0.5  , 0.797, 0.917],\n       [0.083, 0.583, 0.068, 0.083],\n       [0.222, 0.583, 0.085, 0.042],\n       [0.167, 0.458, 0.085, 0.   ],\n       [0.139, 0.417, 0.068, 0.   ],\n       [0.944, 0.25 , 1.   , 0.917],\n       [0.417, 0.25 , 0.508, 0.458],\n       [0.583, 0.5  , 0.593, 0.583],\n       [0.556, 0.542, 0.847, 1.   ],\n       [0.528, 0.333, 0.644, 0.708],\n       [0.167, 0.167, 0.39 , 0.375],\n       [0.167, 0.458, 0.085, 0.   ],\n       [0.389, 0.333, 0.525, 0.5  ],\n       [0.139, 0.458, 0.102, 0.042],\n       [0.722, 0.458, 0.746, 0.833],\n       [0.417, 0.292, 0.695, 0.75 ],\n       [0.278, 0.708, 0.085, 0.042],\n       [0.083, 0.5  , 0.068, 0.042],\n       [0.417, 0.333, 0.695, 0.958],\n       [0.361, 0.417, 0.593, 0.583],\n       [0.556, 0.208, 0.661, 0.583],\n       [0.222, 0.542, 0.119, 0.167],\n       [0.806, 0.417, 0.814, 0.625],\n       [0.472, 0.583, 0.593, 0.625],\n       [0.667, 0.208, 0.814, 0.708],\n       [0.556, 0.208, 0.678, 0.75 ],\n       [0.111, 0.5  , 0.102, 0.042],\n       [0.   , 0.417, 0.017, 0.   ],\n       [0.028, 0.417, 0.051, 0.042],\n       [0.306, 0.792, 0.051, 0.125],\n       [0.361, 0.208, 0.492, 0.417],\n       [0.611, 0.417, 0.763, 0.708],\n       [0.389, 0.25 , 0.424, 0.375],\n       [0.528, 0.583, 0.746, 0.917],\n       [0.5  , 0.375, 0.627, 0.542],\n       [0.194, 0.583, 0.102, 0.125],\n       [0.667, 0.417, 0.678, 0.667],\n       [0.528, 0.083, 0.593, 0.583],\n       [0.194, 0.5  , 0.034, 0.042],\n       [0.167, 0.458, 0.085, 0.   ],\n       [0.917, 0.417, 0.949, 0.833],\n       [0.361, 0.375, 0.441, 0.5  ],\n       [0.5  , 0.333, 0.508, 0.5  ],\n       [0.139, 0.583, 0.153, 0.042],\n       [0.583, 0.375, 0.559, 0.5  ],\n       [0.639, 0.417, 0.576, 0.542],\n       [0.361, 0.417, 0.525, 0.5  ],\n       [0.333, 0.917, 0.068, 0.042],\n       [0.556, 0.333, 0.695, 0.583],\n       [0.139, 0.583, 0.102, 0.042],\n       [0.611, 0.333, 0.61 , 0.583],\n       [0.667, 0.458, 0.576, 0.542],\n       [0.611, 0.417, 0.712, 0.792],\n       [0.222, 0.708, 0.085, 0.125],\n       [0.25 , 0.583, 0.068, 0.042],\n       [0.333, 0.167, 0.475, 0.417],\n       [0.111, 0.5  , 0.051, 0.042],\n       [0.667, 0.458, 0.627, 0.583],\n       [0.167, 0.208, 0.593, 0.667],\n       [0.333, 0.167, 0.458, 0.375],\n       [0.417, 0.292, 0.492, 0.458],\n       [0.556, 0.375, 0.78 , 0.708],\n       [0.556, 0.542, 0.627, 0.625],\n       [0.611, 0.5  , 0.695, 0.792],\n       [0.333, 0.25 , 0.576, 0.458],\n       [0.75 , 0.5  , 0.627, 0.542],\n       [0.611, 0.417, 0.814, 0.875],\n       [0.028, 0.5  , 0.051, 0.042],\n       [0.472, 0.375, 0.593, 0.583],\n       [0.222, 0.75 , 0.085, 0.083],\n       [0.083, 0.458, 0.085, 0.042],\n       [0.667, 0.542, 0.797, 0.833],\n       [0.944, 0.75 , 0.966, 0.875],\n       [0.056, 0.125, 0.051, 0.083],\n       [0.222, 0.75 , 0.102, 0.042],\n       [0.472, 0.083, 0.678, 0.583],\n       [0.583, 0.292, 0.729, 0.75 ],\n       [0.222, 0.75 , 0.153, 0.125],\n       [0.361, 0.333, 0.661, 0.792],\n       [0.389, 0.208, 0.678, 0.792],\n       [0.444, 0.417, 0.542, 0.583],\n       [0.194, 0.417, 0.102, 0.042],\n       [0.444, 0.5  , 0.644, 0.708]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential([\n    Dense(units = 18, input_shape = (10,4), activation = 'relu'),\n    Dense(units = 36, activation = 'relu'),\n    Dense(units = 3, activation = 'softmax')\n])","execution_count":228,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":229,"outputs":[{"output_type":"stream","text":"Model: \"sequential_18\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_54 (Dense)             (None, 10, 18)            90        \n_________________________________________________________________\ndense_55 (Dense)             (None, 10, 36)            684       \n_________________________________________________________________\ndense_56 (Dense)             (None, 10, 3)             111       \n=================================================================\nTotal params: 885\nTrainable params: 885\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=SGD(learning_rate = 0.05), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])","execution_count":230,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x = iris_features, y = iris_labels, validation_split = 0.1, batch_size = 10, epochs = 50, shuffle = True, verbose = 2)","execution_count":231,"outputs":[{"output_type":"stream","text":"Epoch 1/50\n14/14 - 0s - loss: 1.0425 - accuracy: 0.6222 - val_loss: 0.9962 - val_accuracy: 0.6667\nEpoch 2/50\n14/14 - 0s - loss: 0.9713 - accuracy: 0.6148 - val_loss: 0.9220 - val_accuracy: 0.8000\nEpoch 3/50\n14/14 - 0s - loss: 0.9004 - accuracy: 0.6444 - val_loss: 0.8310 - val_accuracy: 0.8000\nEpoch 4/50\n14/14 - 0s - loss: 0.8256 - accuracy: 0.6519 - val_loss: 0.7710 - val_accuracy: 0.8667\nEpoch 5/50\n14/14 - 0s - loss: 0.7483 - accuracy: 0.7037 - val_loss: 0.6733 - val_accuracy: 0.8000\nEpoch 6/50\n14/14 - 0s - loss: 0.6735 - accuracy: 0.7185 - val_loss: 0.5891 - val_accuracy: 0.8000\nEpoch 7/50\n14/14 - 0s - loss: 0.6120 - accuracy: 0.7037 - val_loss: 0.5367 - val_accuracy: 0.8000\nEpoch 8/50\n14/14 - 0s - loss: 0.5580 - accuracy: 0.7259 - val_loss: 0.5050 - val_accuracy: 0.9333\nEpoch 9/50\n14/14 - 0s - loss: 0.5123 - accuracy: 0.9111 - val_loss: 0.4464 - val_accuracy: 0.8000\nEpoch 10/50\n14/14 - 0s - loss: 0.4829 - accuracy: 0.8000 - val_loss: 0.4237 - val_accuracy: 0.9333\nEpoch 11/50\n14/14 - 0s - loss: 0.4532 - accuracy: 0.8593 - val_loss: 0.4009 - val_accuracy: 0.9333\nEpoch 12/50\n14/14 - 0s - loss: 0.4271 - accuracy: 0.9037 - val_loss: 0.3827 - val_accuracy: 1.0000\nEpoch 13/50\n14/14 - 0s - loss: 0.4040 - accuracy: 0.9259 - val_loss: 0.3509 - val_accuracy: 0.9333\nEpoch 14/50\n14/14 - 0s - loss: 0.3839 - accuracy: 0.9185 - val_loss: 0.3571 - val_accuracy: 1.0000\nEpoch 15/50\n14/14 - 0s - loss: 0.3559 - accuracy: 0.9556 - val_loss: 0.3646 - val_accuracy: 0.9333\nEpoch 16/50\n14/14 - 0s - loss: 0.3485 - accuracy: 0.9481 - val_loss: 0.3004 - val_accuracy: 0.9333\nEpoch 17/50\n14/14 - 0s - loss: 0.3239 - accuracy: 0.9185 - val_loss: 0.3294 - val_accuracy: 1.0000\nEpoch 18/50\n14/14 - 0s - loss: 0.3174 - accuracy: 0.9556 - val_loss: 0.2899 - val_accuracy: 1.0000\nEpoch 19/50\n14/14 - 0s - loss: 0.2922 - accuracy: 0.9185 - val_loss: 0.2822 - val_accuracy: 1.0000\nEpoch 20/50\n14/14 - 0s - loss: 0.2810 - accuracy: 0.9333 - val_loss: 0.2529 - val_accuracy: 1.0000\nEpoch 21/50\n14/14 - 0s - loss: 0.2573 - accuracy: 0.9407 - val_loss: 0.2366 - val_accuracy: 1.0000\nEpoch 22/50\n14/14 - 0s - loss: 0.2480 - accuracy: 0.9407 - val_loss: 0.2231 - val_accuracy: 0.9333\nEpoch 23/50\n14/14 - 0s - loss: 0.2321 - accuracy: 0.9481 - val_loss: 0.2221 - val_accuracy: 0.9333\nEpoch 24/50\n14/14 - 0s - loss: 0.2258 - accuracy: 0.9333 - val_loss: 0.2023 - val_accuracy: 1.0000\nEpoch 25/50\n14/14 - 0s - loss: 0.2079 - accuracy: 0.9556 - val_loss: 0.1924 - val_accuracy: 0.9333\nEpoch 26/50\n14/14 - 0s - loss: 0.2028 - accuracy: 0.9481 - val_loss: 0.1965 - val_accuracy: 1.0000\nEpoch 27/50\n14/14 - 0s - loss: 0.1864 - accuracy: 0.9481 - val_loss: 0.2267 - val_accuracy: 1.0000\nEpoch 28/50\n14/14 - 0s - loss: 0.1822 - accuracy: 0.9630 - val_loss: 0.1742 - val_accuracy: 1.0000\nEpoch 29/50\n14/14 - 0s - loss: 0.1703 - accuracy: 0.9556 - val_loss: 0.1667 - val_accuracy: 0.9333\nEpoch 30/50\n14/14 - 0s - loss: 0.1586 - accuracy: 0.9556 - val_loss: 0.1620 - val_accuracy: 1.0000\nEpoch 31/50\n14/14 - 0s - loss: 0.1570 - accuracy: 0.9630 - val_loss: 0.1512 - val_accuracy: 0.9333\nEpoch 32/50\n14/14 - 0s - loss: 0.1589 - accuracy: 0.9481 - val_loss: 0.1556 - val_accuracy: 1.0000\nEpoch 33/50\n14/14 - 0s - loss: 0.1401 - accuracy: 0.9630 - val_loss: 0.1421 - val_accuracy: 1.0000\nEpoch 34/50\n14/14 - 0s - loss: 0.1407 - accuracy: 0.9778 - val_loss: 0.1352 - val_accuracy: 1.0000\nEpoch 35/50\n14/14 - 0s - loss: 0.1310 - accuracy: 0.9630 - val_loss: 0.1357 - val_accuracy: 0.9333\nEpoch 36/50\n14/14 - 0s - loss: 0.1297 - accuracy: 0.9556 - val_loss: 0.1456 - val_accuracy: 0.9333\nEpoch 37/50\n14/14 - 0s - loss: 0.1292 - accuracy: 0.9630 - val_loss: 0.1228 - val_accuracy: 1.0000\nEpoch 38/50\n14/14 - 0s - loss: 0.1261 - accuracy: 0.9556 - val_loss: 0.1190 - val_accuracy: 1.0000\nEpoch 39/50\n14/14 - 0s - loss: 0.1193 - accuracy: 0.9630 - val_loss: 0.1349 - val_accuracy: 0.9333\nEpoch 40/50\n14/14 - 0s - loss: 0.1236 - accuracy: 0.9481 - val_loss: 0.1394 - val_accuracy: 0.9333\nEpoch 41/50\n14/14 - 0s - loss: 0.1196 - accuracy: 0.9556 - val_loss: 0.1382 - val_accuracy: 0.9333\nEpoch 42/50\n14/14 - 0s - loss: 0.1062 - accuracy: 0.9704 - val_loss: 0.1312 - val_accuracy: 1.0000\nEpoch 43/50\n14/14 - 0s - loss: 0.1069 - accuracy: 0.9778 - val_loss: 0.1129 - val_accuracy: 0.9333\nEpoch 44/50\n14/14 - 0s - loss: 0.1106 - accuracy: 0.9556 - val_loss: 0.1140 - val_accuracy: 0.9333\nEpoch 45/50\n14/14 - 0s - loss: 0.0960 - accuracy: 0.9852 - val_loss: 0.1040 - val_accuracy: 1.0000\nEpoch 46/50\n14/14 - 0s - loss: 0.0977 - accuracy: 0.9778 - val_loss: 0.1036 - val_accuracy: 1.0000\nEpoch 47/50\n14/14 - 0s - loss: 0.0966 - accuracy: 0.9852 - val_loss: 0.1222 - val_accuracy: 0.9333\nEpoch 48/50\n14/14 - 0s - loss: 0.1102 - accuracy: 0.9556 - val_loss: 0.0990 - val_accuracy: 1.0000\nEpoch 49/50\n14/14 - 0s - loss: 0.0911 - accuracy: 0.9704 - val_loss: 0.1619 - val_accuracy: 0.9333\nEpoch 50/50\n14/14 - 0s - loss: 0.0878 - accuracy: 0.9704 - val_loss: 0.0960 - val_accuracy: 1.0000\n","name":"stdout"},{"output_type":"execute_result","execution_count":231,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f550c755e10>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('iris_dataset.model')","execution_count":232,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}
